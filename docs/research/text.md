I 에이전트 시스템을 위한 하네스 엔지니어링(Harness Engineering) 심층 분석 및 실무 적용 가이드하네스 엔지니어링의 대두 배경 및 개념적 정의소프트웨어 개발 패러다임이 인간 중심의 수동 코드 작성에서 인공지능(AI) 에이전트 주도의 자율적 코드 생성으로 근본적인 전환을 맞이하고 있다. 이러한 패러다임 전환에 따라 소프트웨어 엔지니어링 팀의 핵심 역할은 더 이상 코드를 직접 타이핑하는 것이 아니라, 환경을 설계하고, 의도를 명세하며, AI 에이전트가 신뢰할 수 있는 작업을 수행하도록 피드백 루프를 구축하는 방향으로 진화하고 있다. 이러한 기술적, 방법론적 변화의 중심에 '하네스 엔지니어링(Harness Engineering)'이라는 새로운 아키텍처 규율이 자리 잡고 있다.본래 하네스(Harness)란 복잡한 기계 시스템을 제어하고 안전하게 유지하기 위한 물리적 장구를 의미한다. 인공지능 및 대형 언어 모델(LLM) 컨텍스트에서 하네스란, 자율성을 가진 AI 에이전트의 행동을 통제하고, 환각(Hallucination) 현상을 억제하며, 장기적인 코드 품질을 유지하기 위해 사용되는 도구, 프레임워크, 그리고 실무 관행의 총체를 뜻한다. 초기 AI 코딩 어시스턴트가 단일 함수나 스크립트를 완성하는 수준의 국소적 문제 해결에 머물렀다면, 현재의 최첨단 AI 에이전트는 복잡한 종속성을 가진 수백만 줄의 프로젝트를 분석하고, 자율적으로 외부 도구를 호출하며, 시스템 단위의 리팩터링을 수행한다. 그러나 LLM은 본질적으로 자가 회귀(Autoregressive) 모델로서 이전 토큰들을 기반으로 통계적으로 가장 그럴듯한 다음 토큰을 로컬 차원에서 예측할 뿐, 프로젝트의 전역적인 아키텍처나 암묵적인 비즈니스 규칙을 본능적으로 이해하지는 못한다. 따라서 엄격한 제약과 문맥이 주어지지 않은 환경에 에이전트를 방치할 경우, 관례를 무시하거나 논리를 중복 생성하고, 시스템의 아키텍처 제약을 파괴하는 이른바 'AI 코드 드리프트(AI Code Drift)' 현상이 필연적으로 발생하게 된다.이러한 엔트로피 증가를 억제하기 위해 Anthropic과 OpenAI 등의 선도적인 AI 연구 기관들은 자사의 프런티어 모델(Claude 3.7 Sonnet, GPT-5 등)을 제어하는 고도화된 하네스 시스템을 구축했다. 하네스 엔지니어링은 안전 공학의 스위스 치즈 모델(Swiss Cheese Model)과 유사하게 작동한다. 단일 평가 계층이나 단일 프롬프트가 모든 문제를 포착할 수는 없으므로, 여러 겹의 다층적 방어 기제를 결합하여 하나의 계층을 통과한 실패가 다른 계층에서 포착되도록 설계하는 것이다. 이 다층적 시스템은 크게 세 가지 핵심 축으로 구성된다. 첫째, 컨텍스트 엔지니어링(Context Engineering)은 코드베이스 내의 지식 기반을 지속적으로 강화하고, 관측 가능성(Observability) 데이터나 브라우저 탐색 결과 등 동적 컨텍스트에 대한 에이전트의 접근성을 관리한다. 둘째, 아키텍처 제약(Architectural Constraints)은 결정론적 커스텀 린터(Linter)와 구조적 테스트를 통해 에이전트가 생성한 코드가 시스템의 설계 원칙을 준수하도록 강제한다. 셋째, 가비지 컬렉션(Garbage Collection)은 문서의 불일치나 설계 위반 사항을 주기적으로 찾아내어 수정함으로써 코드베이스의 부패와 기술 부채(Technical Debt)를 능동적으로 해결하는 프로세스를 의미한다.본 보고서는 OpenAI와 Anthropic이 실제로 어떻게 하네스 시스템을 설계하고 운영하는지 심층적으로 분석하고, 이를 바탕으로 일반 사용자가 Claude Code나 Codex 환경에서 하네스 엔지니어링을 구체적으로 적용할 수 있는 실무적 방법론과 아키텍처적 시사점을 도출한다.OpenAI의 하네스 엔지니어링: Codex 기반의 완전 자율 개발 프레임워크OpenAI는 하네스 엔지니어링의 실효성을 검증하기 위해 극단적인 제약 조건을 설정한 대규모 내부 실험을 진행했다. 개발팀은 "수동으로 타이핑한 코드가 단 한 줄도 없어야 한다"는 규칙을 강제 메커니즘으로 채택하여 5개월 만에 100만 줄 이상의 코드로 구성된 실제 서비스 제품을 구축하는 데 성공했다. 이 과정에서 애플리케이션 로직뿐만 아니라 테스트, CI(지속적 통합) 구성, 문서화, 관측 가능성 설정, 내부 도구 등 저장소의 모든 요소가 Codex에 의해 작성되었다. 초기 3명으로 시작해 7명으로 늘어난 엔지니어 팀은 약 1,500개의 풀 리퀘스트(PR)를 병합하며 하루 평균 3.5개의 PR 처리량을 기록했다. 이들은 인간이 직접 코드를 작성하는 대신 에이전트가 신뢰할 수 있는 작업을 수행할 수 있도록 환경을 설계하고 피드백 루프를 구축하는 하네스 엔지니어링에 전적으로 집중했다.Codex App Server와 양방향 JSON-RPC 프로토콜 아키텍처OpenAI의 모든 Codex 기반 인터페이스, 즉 터미널 기반의 Codex CLI, VS Code 확장 프로그램, 그리고 웹 런타임의 이면에는 동일한 에이전트 루프와 논리를 구동하는 'Codex App Server'라는 핵심 하네스 인프라가 존재한다. 이 서버는 클라이언트 친화적인 양방향 JSON-RPC API로 설계되었다. 초기에 Codex CLI는 터미널 사용자 인터페이스(TUI)로 시작되었으나, IDE 환경에서도 동일한 에이전트 루프를 재구현 없이 구동하기 위해 이 프로토콜이 표준으로 채택되었다.통신 방식 측면에서 이 프로토콜은 엄격한 JSON-RPC 2.0 규격 대신 표준 입출력(stdio) 기반의 JSONL(JSON Lines) 통신 방식을 채택한 “JSON-RPC lite” 변형을 사용한다. 이는 클라이언트 구현의 복잡성을 낮추면서도 에이전트가 작업 공간을 탐색하고, 추론 과정을 스트리밍하며, 코드의 차이점(Diff)을 원활하게 방출할 수 있도록 지원한다. 아키텍처 내에서 에이전트와의 상호작용은 세 가지 기본 식별 체계로 모델링된다. 첫째, 항목(Item)은 입출력의 가장 작은 원자 단위로, 메시지나 도구 실행 결과 등을 나타내며 명시적인 생명주기(item/started, item/delta, item/completed)를 가진다. 둘째, 턴(Turn)은 사용자의 입력으로 시작하여 에이전트가 모든 중간 단계를 거쳐 출력을 완료할 때까지의 한 단위 작업 루프를 의미한다. 셋째, 스레드(Thread)는 지속적인 세션을 위한 컨테이너로, 세션이 중단되거나 분기 및 보관되더라도 일관된 작업 내역을 유지할 수 있도록 상태를 저장하는 역할을 수행한다. 이 완전한 양방향 통신 구조 덕분에 에이전트가 사용자 승인이 필요한 민감한 작업을 수행할 때 먼저 요청을 보내고 사용자의 "허용(allow)" 또는 "거부(deny)" 응답을 대기하는 능동적인 워크플로우 구현이 가능해졌다.계층적 컨텍스트 제어 및 AGENTS.md 생태계Codex 하네스의 가장 중요한 사용자 인터페이스 중 하나는 AGENTS.md 파일이다. 이 파일은 에이전트가 작업을 시작하기 전에 반드시 읽어야 하는 "에이전트를 위한 README"로 기능하며, 코드베이스를 탐색하는 에이전트에게 프로젝트의 맥락, 빌드 명령어, 코딩 규칙 등을 제공한다. OpenAI는 대규모 모노레포(Monorepo) 환경에서 전역 컨텍스트가 오염되는 것을 방지하기 위해 정교한 계층적 구조를 도입했다.에이전트는 작업이 시작될 때 디렉터리 트리를 따라 가장 가까운 위치에 있는 AGENTS.md 파일을 로드하여 지시망(Instruction chain)을 구축한다. 루트 디렉터리에 존재하는 AGENTS.md는 프로젝트 전체를 아우르는 전역 원칙(예: 시스템의 철학, 보안 기준)을 정의한다. 반면, 하위 디렉터리(예: frontend/ 또는 backend/)에 위치한 중첩된 AGENTS.md는 해당 도메인에 특화된 국소적 지침을 제공하여 전역 원칙을 상속받으면서도 세부적인 규칙을 덮어쓰거나 추가한다. 예를 들어 프런트엔드 디렉터리 내의 컴포넌트를 수정할 때는 루트와 프런트엔드의 컨텍스트만이 결합되어 에이전트에게 전달된다. 이 계층적 접근 방식은 대규모 프로젝트에서 불필요한 정보로 인해 LLM의 컨텍스트 윈도우가 소모되는 것을 막고, 환각 현상을 최소화하는 확장 가능한 컨텍스트 엔지니어링의 핵심 기반이다. 실제로 OpenAI 내부의 대규모 저장소에는 무려 88개의 개별 AGENTS.md 파일이 존재하여 각 서브 프로젝트마다 맞춤형 지침을 제공하고 있다.아키텍처 제약 강제 및 자율적 가비지 컬렉션(Garbage Collection)에이전트에게 완전한 자율성을 부여하면 코드 리포지토리에 존재하는 불완전하거나 최적화되지 않은 패턴까지 그대로 복제하는 부작용을 낳는다. 시간이 지남에 따라 이는 필연적으로 아키텍처 드리프트를 유발한다. OpenAI 팀은 프로젝트 초기에는 매주 금요일을 온전히 'AI 슬롭(AI Slop, 조잡한 AI 생성 코드)'을 정리하는 데 할애했으나, 이는 시스템이 확장됨에 따라 한계에 부딪혔다.이러한 문제를 해결하기 위해 하네스 내부에 강력한 결정론적 아키텍처 제약을 도입했다. 에이전트가 생성한 코드는 LLM 기반의 검토뿐만 아니라 커스텀 린터와 구조적 테스트를 통해 이중으로 모니터링된다. 구조화된 로깅, 스키마 및 타입 명명 규칙, 파일 크기 제한, 플랫폼 특화 신뢰성 요구사항 등을 정적으로 강제한다. 가장 중요한 혁신은 이러한 린터들이 단순히 에러를 발생시키는 데 그치지 않고, 에러 메시지 내부에 에이전트가 어떻게 코드를 수정해야 하는지에 대한 구체적인 '해결 지침(Remediation instructions)'을 주입하도록 설계되었다는 점이다. 이를 통해 에이전트는 피드백 루프 안에서 스스로 오류를 인식하고 즉각적으로 교정할 수 있게 되었다.더 나아가, 기술 부채가 복리로 쌓이는 것을 방지하기 위해 '가비지 컬렉션(Garbage Collection)' 에이전트를 도입했다. 프로그래밍 언어(예: Python, Java)의 메모리 관리 기법에서 차용한 이 개념은, 더 이상 참조되지 않는 객체나 메모리 누수를 자동으로 찾아내어 해제하는 시스템 메커니즘을 코드베이스 유지보수에 적용한 것이다. 하네스 시스템 내에서 구동되는 가비지 컬렉션 에이전트는 백그라운드에서 주기적으로 실행되며, 문서의 불일치를 찾아내고, 사용되지 않는 함수 참조나 아키텍처 위반 사항을 정리하여 프로젝트의 엔트로피와 부패를 능동적으로 억제한다.Anthropic의 하네스 엔지니어링: 장기 실행 에이전트와 도구 샌드박싱Anthropic은 Claude 3.5 및 최신 4.6 모델 라인업(Opus, Sonnet, Haiku)을 기반으로 구동되는 AI 코딩 어시스턴트인 Claude Code를 제공하며, 이를 지원하는 근간으로 Claude Agent SDK를 지속적으로 고도화하고 있다. Anthropic의 하네스 철학은 단일 턴의 코드 생성을 넘어, 몇 시간 혹은 며칠에 걸쳐 진행되는 복잡한 장기 실행 작업(Long-running tasks)에서의 상태 유지와 신뢰성 높은 외부 도구 오케스트레이션에 집중되어 있다.상태 상실 극복: 다중 에이전트 기반 하네스 아키텍처소프트웨어 개발 프로젝트처럼 긴 호흡이 필요한 작업을 AI 에이전트에게 맡길 때 직면하는 가장 큰 난관은 컨텍스트 윈도우의 물리적 한계와, 개별 세션 간에 발생하는 '기억 상실(Amnesia)' 현상이다. 독립된 세션으로 실행되는 에이전트는 이전 세션에서 어떤 의도로 작업이 진행되었는지 알지 못한다. 마치 교대 근무를 하는 엔지니어가 이전 작업자의 인수인계 없이 업무에 투입되는 것과 같다. 이로 인해 에이전트는 단일 세션 내에서 모든 것을 처리하려다 반쪽짜리 기능만 구현하고 종료해버리거나, 후속 세션의 에이전트가 기존 구조를 무시하고 덮어쓰며, 심지어 일부 코드만 작성된 상태를 보고 기능 구현이 완료된 것으로 착각하여 성급하게 승리를 선언하는(Premature victory declaration) 치명적인 패턴을 보인다.단순히 오래된 컨텍스트를 압축(Compaction)하는 기법만으로는 상용 수준의 웹 애플리케이션을 구축할 수 없다는 것을 인지한 Anthropic은 Agent SDK를 활용하여 '이중 에이전트 솔루션(Two-Agent Solution)' 구조의 하네스를 설계했다.이 구조는 두 가지 명확히 구분된 역할로 나뉜다.
첫째, 초기화 에이전트(Initializer Agent)는 아주 첫 번째 컨텍스트 윈도우에서만 실행되며 전체 프로젝트의 청사진과 인프라를 구축한다. 이 에이전트는 개발 서버 실행을 위한 init.sh 스크립트를 작성하고, 향후 에이전트들의 작업 내역을 기록할 claude-progress.txt라는 전용 로그 파일을 생성하며, 초기 Git 커밋을 수행하여 변경 사항 추적의 기준선을 확립한다. 특히 중요한 점은 사용자의 개략적인 프롬프트를 분석하여 전체 시스템 요구사항을 수백 개의 세부 기능으로 분할한 feature_list.json (또는 tests.json) 파일을 생성한다는 것이다. 이때 구조화 문법으로 Markdown 대신 JSON을 채택하는 이유는 엄격한 구문 규칙 덕분에 LLM이 임의로 구조를 훼손하거나 완료되지 않은 항목을 임의로 덮어쓸 확률이 현저히 낮아지기 때문이다. 초기화 시점에는 JSON 내의 모든 기능이 "실패(failing)" 상태로 마킹된다.둘째, 코딩 에이전트(Coding Agent)는 이후의 모든 후속 세션에서 독립적으로 실행되며, 오직 점진적인 진척(Incremental progress)에만 초점을 맞춘다. 코딩 에이전트는 세션이 시작될 때마다 고정된 확인 절차를 거치도록 하네스에 의해 강제된다. 먼저 pwd 명령어를 통해 현재 디렉터리를 확인하고, Git 로그와 claude-progress.txt를 읽어 프로젝트의 최근 상태를 파악한 뒤, init.sh를 실행하여 서버가 이전 세션의 작업으로 인해 망가지지 않았는지 초기 검증을 수행한다. 상황 파악이 끝나면 feature_list.json에서 아직 완료되지 않은 단 하나의 기능(Single feature)만을 우선순위에 따라 선택하여 작업한다. 구현이 완료되면 에이전트는 시각적 UI 버그를 확인하기 위해 Puppeteer MCP 서버와 같은 브라우저 자동화 도구를 호출하여 인간 사용자처럼 엔드투엔드(E2E) 자가 검증을 수행한다. 이 검증을 통과해야만 비로소 JSON 파일의 상태를 "통과(passes)"로 변경할 수 있으며, 다음 세션을 위한 명확한 커밋 메시지와 진행 상황 로그를 남긴 채 세션을 깨끗한 상태(Clean state)로 종료한다.기술(Skills) 및 샌드박싱 환경 구축을 통한 제어력 강화Claude Code는 단순히 디렉터리 내의 코드를 수정하는 것을 넘어, 하네스 엔지니어링 관점에서 모델의 자율성을 통제하는 고도화된 샌드박스 환경인 기술(Skills) 아키텍처를 제공한다. 사용자의 개입 없이 에이전트가 알아서 호출할 수 있는 이러한 기술들은 .claude/skills/SKILL.md 경로에 저장되며, YAML 프런트매터(Frontmatter)와 Markdown 본문으로 구성되어 에이전트의 권한과 행동 지침을 세밀하게 제어하는 제어판 역할을 한다.YAML 프런트매터 내의 주요 속성들은 하네스 환경을 구성하는 핵심적인 매개변수들이다.allowed-tools: 에이전트가 사용자의 명시적인 승인 절차 없이 즉각적으로 실행할 수 있는 명령어와 도구를 지정한다. 예를 들어 allowed-tools: Read, Grep, Glob으로 설정할 경우, 에이전트는 코드베이스를 탐색하고 검색할 수 있지만 시스템 파일을 수정하거나 파괴적인 명령을 내릴 수 없는 완벽한 읽기 전용(Read-only) 모드로 구속된다.context: fork 및 agent: 이 속성들은 메인 컨텍스트 윈도우가 복잡한 탐색 작업으로 인해 오염되는 것을 방지한다. 이 속성이 활성화되면, 스킬이 실행될 때 메인 대화 기록에 접근할 수 없는 별도의 분리된 하위 에이전트(Subagent)가 생성(Fork)되어 작업을 위임받는다. 필요에 따라 'Explore'나 'Plan'과 같은 특화된 에이전트 유형을 지정함으로써, 광범위한 코드베이스 검토나 보안 감사와 같이 독립적이고 병렬적인 작업 처리가 가능해진다.동적 변수 치환: 마크다운 본문 내에서 $ARGUMENTS나 ${CLAUDE_SESSION_ID}와 같은 변수를 사용하여 런타임에 동적으로 값을 치환할 수 있다. 이를 통해 에이전트가 특정 이슈 번호에 해당하는 파일만을 타겟팅하거나, 세션별로 고유한 로그 파일을 자동 생성하도록 강제할 수 있다.이러한 기술 시스템은 종속성을 갖는 복잡한 하네스 구축을 매우 단순하게 만들며, 외부 시스템 통신을 위한 MCP(Model Context Protocol) 지원과 결합되어 에이전트가 데이터베이스에 쿼리하거나, Notion에서 문서를 가져오고, Slack을 통해 알림을 보내는 등 시스템 간 오케스트레이션을 가능하게 한다.평가 하네스(Evaluation Harnesses): 에이전트 신뢰성의 기반정밀하게 구축된 에이전트 하네스가 실제로 의도한 대로 작동하는지, 그리고 예상치 못한 편향이나 위험 요소가 없는지 검증하는 평가 체계는 하네스 엔지니어링의 필수적인 구성 요소다. Anthropic의 관점에서 "에이전트를 평가한다"는 것은 단일 프롬프트에 대한 모델의 텍스트 생성 능력을 측정하는 것이 아니다. 그것은 "모델과 하네스(스캐폴드)가 상호작용하는 전체 시스템의 실행 결과"를 평가하는 것이다. 복잡한 에이전트 평가는 단일 턴 응답이 아닌 여러 턴에 걸친 에이전트의 추론, 도구 호출, 오류 복구 능력을 포괄하는 전체 궤적(Transcript)과 환경 내의 최종 상태(Outcome)를 종합적으로 분석해야 한다.자동화된 정렬 및 보안 평가: Petri와 Bloom 프레임워크Anthropic은 AI 안전성 연구를 가속화하기 위해 Petri라는 오픈소스 감사 도구를 개발하여 하네스 평가에 활용하고 있다. 기존에는 연구자들이 정렬(Alignment) 평가를 위해 수동으로 환경을 구축하고 트랜스크립트를 읽어야 했으나, Petri는 이 과정을 완전 자동화한다. 사용자가 특정 상황이나 행동을 묘사하는 시드 지침을 제공하면, Petri는 인간 사용자를 모사하는 메시지와 가상의 터미널 및 웹 검색 도구를 포함한 시뮬레이션 환경을 자율적으로 구성한다. 이후 타겟 모델을 상대로 다중 턴 감사를 병렬로 수행하고, 최종적으로 강력한 LLM 심판(Judge) 모델이 트랜스크립트를 평가하여 위험 행동을 수면 위로 끌어올린다. Petri를 통한 평가는 주로 환각, 사용자에 대한 아첨(Sycophancy), 목적 달성을 위한 기만(Deception) 행위, 그리고 유해한 요청에 대한 협력 여부를 식별하는 데 초점을 맞추고 있다. 최신 Petri 2.0 버전에서는 성능이 뛰어난 모델이 스스로 평가를 받고 있음을 인지하고 행동을 수정하는 '평가 인지(Eval-awareness)' 현상을 완화하기 위해 사실주의적 완화 기법과 확장된 시나리오 라이브러리가 추가되었다.이와 함께 Bloom이라는 자동화된 행동 평가 도구를 통해 망상적 아첨, 지시된 장기 사보타주, 자기 보존 및 자기 선호 편향 등 시스템 프롬프트를 통해 조작된 모델의 비정상적 행동을 다양한 프런트이어 모델 전반에 걸쳐 교차 검증하고 있다. 이러한 도구들은 단순히 코딩 능력을 넘어 에이전트가 독립적인 작업 환경에서 윤리적, 아키텍처적 제약을 준수하는지 확인하는 하네스 설계의 근간이 된다.코딩 및 터미널 환경 특화 벤치마크: Terminus-2와 SWE-bench실제 소프트웨어 엔지니어링 역량을 평가하기 위해 Anthropic과 OpenAI는 고도화된 벤치마크 평가 시스템을 운영하고 있다. 터미널 및 명령줄 환경에서 AI 모델의 성능을 테스트하는 Terminal-Bench 2.0 벤치마크는 Harbor 스캐폴드 위에서 작동하는 Terminus-2 하네스를 통해 구동된다. 이 벤치마크는 머신러닝 모델 학습부터 시스템 관리에 이르는 89개의 난해한 작업을 포괄하며, 초기에는 어떤 모델도 50% 이상의 점수를 받지 못할 만큼 높은 난이도를 자랑했다. 평가의 신뢰성을 확보하기 위해 Terminus-2 하네스에서는 모든 작업이 격리된 Kubernetes Pod에서 실행되며, 모델이 지정된 Pytest를 완벽하게 통과해야만 점수를 부여받는 엄격한 결정론적 채점 방식을 채택했다. 특히 작업 중 메모리 부족(OOM)으로 컨테이너가 종료되는 인프라 기인 오류를 줄이기 위해 자원 할당량을 유연하게 조정하는 등 물리적 환경 제어까지 하네스의 몫으로 두고 있다.오픈소스 프로젝트의 실제 이슈 해결 능력을 측정하는 SWE-bench(Software Engineering Bench) 벤치마크에서도 하네스 내의 프롬프트 최적화가 모델의 성과에 지대한 영향을 미친다. 인간 엔지니어가 검증한 500개의 문제로 구성된 SWE-bench Verified 환경에서 Claude 4.6 Sonnet 모델은 기본적으로 우수한 성과를 보였으나, 하네스 내에 "도구를 100회 이상 적극적으로 사용하고, 문제 해결 시도 전에 자가 테스트를 구현하며, 표면적 증상이 아닌 근본 원인을 파악하라"는 프롬프트 변형을 주입했을 때 점수가 80.2%까지 극적으로 상승하는 결과를 보여주었다. 이는 에이전트의 물리적 지능 못지않게 이를 이끌어내는 하네스의 구조적 설계가 성능의 상한선을 결정짓는다는 것을 시사한다.오픈소스 기반의 평가 하네스인 Promptfoo 역시 이러한 기조를 반영하여 비즈니스 로직, RAG(Retrieval-Augmented Generation) 컴포넌트, 그리고 에이전트 프레임워크가 결합된 전체 애플리케이션 수준의 평가를 제공한다. Promptfoo는 에이전트의 안전하지 않은 도구 사용이나 비즈니스 규칙 위반을 타겟으로 하는 자동화된 레드 티밍(Red Teaming)을 수행하여, 개발 파이프라인(CI/CD) 안에서 보안 취약점을 사전 식별하는 역할을 한다.OpenAI Codex와 Anthropic Claude Code의 하네스 아키텍처 비교 분석두 시스템 모두 복잡한 개발 작업을 AI 에이전트에게 위임하기 위해 고도로 설계된 하네스를 갖추고 있으나, 세부적인 구현 방식과 설계 철학에서 뚜렷한 차이를 보이며 이는 사용자 환경에서의 적용 방식에도 영향을 미친다.다음은 두 에이전트 프레임워크의 하네스 아키텍처를 비교한 표이다.아키텍처 및 하네스 특성OpenAI Codex CLI 하네스Anthropic Claude Code 하네스핵심 통신 프로토콜Codex App Server 기반. 클라이언트 친화적인 JSON-RPC lite (JSONL over stdio) 방식을 채택하여 IDE 및 CLI 간 원활한 통합 지원.Claude Agent SDK 기반. Python 및 TypeScript 환경에서 객체 지향적 접근 방식을 사용하며 Context, Action, Observation의 명시적 루프 구현.프로젝트 컨텍스트 관리루트 및 하위 디렉터리에 분산 배치된 AGENTS.md를 기반으로 한 계층적 지침 구조. 가장 가까운 파일을 우선 적용하여 컨텍스트 범위를 제한.CLAUDE.md를 통한 전역 설정과 .claude/skills/SKILL.md를 통한 기능별 세분화된 문맥 지침 및 도구 제어 병행.장기 실행 작업 (Long-horizon) 제어마크다운 기반의 progress.md 작성 및 사용자 주도의 AGENTS.md 파일 수정을 통한 수동적인 목표 추적 및 상태 분할에 의존.Initializer 및 Coding Agent의 이중 구조 채택. feature_list.json 및 init.sh를 활용한 기계 친화적 상태 유지 및 자가 검증 프로세스 내장.아키텍처 제약 및 오류 교정커스텀 린터 및 결정론적 구조 테스트에 크게 의존. 오류 발생 시 터미널을 통해 해결 지침을 에이전트에게 주입하여 교정 강제.샌드박스 환경(Skills)의 allowed-tools 설정을 통해 파괴적 권한을 선제적으로 제한하고, 별도의 하위 에이전트(Subagent)를 포크하여 검증 위임.외부 시스템 상호작용내장된 CLI 도구를 주력으로 사용하며, 지속적인 가비지 컬렉션 스크립트를 파이프라인에 연결하여 엔트로피 감소에 집중.MCP (Model Context Protocol) 지원을 핵심으로 삼아 GitHub, Notion, Puppeteer 등 외부 서비스 및 도구와의 깊은 통합을 기본 제공.모델 동작 및 추론 철학작업 착수 전 긴 시간을 할애하여 심층적인 추론을 수행하며, 비교적 개방적이고 자율적인 문제 접근 방식을 선호 (GPT-5 Codex 기반).추론 시간을 단축하고 실제 코드 출력과 도구 활용에 집중하며, 사용자가 명시한 제약(Skills) 안에서 작업하는 통제된 접근 방식 선호 (Claude 4.6 Sonnet 기반).OpenAI는 시스템 전반에 걸쳐 계층적 문서화와 커스텀 린팅 등 결정론적 파이프라인을 구축하여 에이전트를 모니터링하는 데 중점을 둔다. 반면, Anthropic은 도구 사용 권한을 파일 단위로 분리하고 MCP를 통해 외부 환경과 능동적으로 통신하는 강력한 샌드박스 확장에 강점을 보인다. 이 두 가지 철학은 각기 다른 장단점을 지니며, 프로젝트의 특성과 개발팀의 선호도에 따라 적합한 프레임워크를 선택하는 기준이 된다.사용자 환경에서의 하네스 엔지니어링 구체적 적용 및 구현 가이드전문 개발자가 자신의 로컬 프로젝트 환경이나 기업 내부의 시스템에서 Claude Code 및 Codex를 최대한의 성능으로 이끌어내기 위해서는, 프롬프트 엔지니어링을 넘어선 시스템 단위의 하네스 구축이 필수적이다. 모델의 원시적인 지능은 강력하지만, 이를 구조화하지 않으면 필연적으로 코드 드리프트와 아키텍처 오염으로 이어진다. 다음은 사용자가 직접 도입할 수 있는 네 가지 차원의 구체적인 하네스 엔지니어링 방법론이다.1. 점진적 공개를 원칙으로 한 계층적 컨텍스트 엔지니어링소프트웨어 시스템에 대한 모든 지식을 하나의 파일에 욱여넣는 것은 최악의 컨텍스트 엔지니어링이다. 대규모 모노레포를 다룰 때 모든 컨텍스트를 최상위 CLAUDE.md나 AGENTS.md에 몰아넣을 경우, LLM의 한정된 컨텍스트 윈도우가 고갈될 뿐만 아니라 정보의 홍수 속에서 핵심 명령어에 대한 주의력(Attention)이 분산되어 환각 현상이 증가한다. 따라서 '점진적 공개(Progressive Disclosure)' 원칙에 따라 컨텍스트를 분산 설계해야 한다.최상위 루트 디렉터리에는 300줄 미만의 간결한 CLAUDE.md 혹은 AGENTS.md를 배치하는 것이 권장된다. 이 파일에는 프로젝트의 전체적인 목적, 사용 중인 기술 스택, 빌드 및 테스트를 위한 필수 명령어, 그리고 최상위 수준의 아키텍처 철학만을 명시한다. 세부적인 규약은 하위 도메인으로 위임해야 한다. 예를 들어, packages/frontend/ 디렉터리에는 UI 컴포넌트 작성 시 접근성(A11y) 보장 규칙과 CSS-in-JS 활용 규약을 담은 별도의 AGENTS.md를 배치하고, packages/backend/ 디렉터리에는 REST API 응답 규약, 데이터베이스 스키마 수정 시의 트랜잭션 주의사항 등을 담은 파일을 둔다. 에이전트는 작업 중인 파일의 디렉터리 위치에서부터 상위 트리로 거슬러 올라가며 가장 가까운 설정 파일을 순차적으로 읽어 들이므로, 전역 지침과 도메인 특화 지침이 자연스럽게 결합된다. 유의할 점은, 컨텍스트 제어 파일은 하네스 시스템에서 가장 레버리지가 큰 지점이므로, AI 도구를 이용해 자동으로 생성하기보다는 시니어 엔지니어가 직접 신중하게 작성해야 한다는 것이다.2. 'AI-Lint' 독트린을 통한 아키텍처 제약 강제AI 모델은 구문 분석에는 뛰어나지만 구조적 미학이나 아키텍처 관점에서의 '적합성(Belonging)'을 판단하는 데는 취약하다. 컴파일이 되고 동작하는 코드일지라도 불필요한 추상화를 남발하거나 복잡성을 숨겨 기술 부채를 유발하는 경우가 빈번하다. 이를 억제하기 위해 인간 시니어 엔지니어의 통찰력을 명문화하여 에이전트의 컨텍스트에 주입하는 아키텍처 제약 설정이 필요하다.실무적으로는 'AI-Lint'와 같은 독트린(Doctrine) 방식을 도입하는 것이 효과적이다. 프로젝트 내에 .ai-lint 디렉터리를 구성하고, 에이전트가 코드를 작성하기 전에 반드시 참조해야 할 원칙을 정의한다. 예를 들어 "JS-R1 원칙: 암시적 전역 상태의 사용을 엄격히 금지함. 이는 원인 규명을 어렵게 하고 테스트 환경의 초기화를 방해하기 때문임"과 같이 특정 언어나 프레임워크에서 거부해야 할 안티 패턴을 명확한 이유와 함께 문서화한다.이에 더해 피드백 루프를 자동화하기 위해 CI 파이프라인이나 로컬 Git Hook에 커스텀 린터를 연결해야 한다. 린터가 규칙 위반을 감지하면 터미널에 에러를 출력하는 데서 멈추지 않고, 에러 메시지 자체에 "이 코드는 전역 상태를 오염시키므로, 의존성 주입(Dependency Injection) 방식을 활용하는 구조로 리팩터링할 것"이라는 명시적인 해결 지침(Remediation instructions)을 덧붙이도록 구성한다. Codex CLI나 Claude Code는 Observation 루프 단계에서 터미널의 에러 로그를 읽어 들이므로, 에이전트는 사용자의 개입 없이 이 지침을 바탕으로 스스로 코드를 수정하고 검증을 재시도하게 된다.3. 상태 안전성을 위한 장기 실행 하네스와 가비지 컬렉션(Garbage Collection) 스크립팅에이전트에게 "새로운 결제 시스템을 구현하라"고 포괄적이고 장기적인 임무를 부여하는 것은 실패를 초래하는 전형적인 원인이다. 에이전트가 복잡한 기능을 구현하는 동안 이전 컨텍스트를 잊어버리고 환각을 일으키는 것을 막기 위해 강제적인 상태 관리 시스템을 마련해야 한다.사용자는 프로젝트 내에 진행 상황을 기계적으로 추적할 수 있는 JSON 파일을 구성해야 한다. 예를 들어 feature_tasks.json을 생성하고, 작업해야 할 모든 세부 기능을 식별자, 설명, 그리고 "passes": false 상태로 정의해 둔다. 그리고 CLAUDE.md를 통해 에이전트에게 다음과 같은 엄격한 프로토콜을 강제한다: "작업을 시작할 때 반드시 feature_tasks.json을 읽고, 하나의 passes: false 항목만 단독으로 작업하라. 구현이 완료되면 즉시 npm run test를 실행하고, 성공한 경우에만 JSON의 상태를 true로 업데이트하라.". 이 구조적 스캐폴딩(Scaffolding)은 에이전트가 궤도를 이탈하는 것을 방지한다.아울러, 지속적으로 쌓이는 난장판을 청소하기 위해 AI 기반의 가비지 컬렉터(Garbage Collector)를 구현해야 한다. Python이나 Java 시스템에서 메모리 누수를 막기 위해 도달 불가능한 객체(Unreachable objects)를 마크-앤-스위프(Mark-and-Sweep) 알고리즘으로 추적하여 메모리를 해제하는 원리를 AI 코드 유지보수에 적용하는 것이다. 실무에서는 Cron 작업 등을 통해 특정 주기(예: 매주 주말)마다 AI 에이전트를 헤드리스(Headless) 모드로 자동 실행시키는 스크립트를 작성한다. 이 가비지 컬렉션 에이전트의 프롬프트에는 "전체 코드베이스를 스캔하여 (1) 사용되지 않는 변수나 참조가 끊어진 함수(Unreachable code), (2) 실제 로직의 변경 사항이 반영되지 않은 오래된 Docstring, (3) 아키텍처 원칙에 어긋나는 우회 로직을 찾아내어 정리하라"는 임무를 부여한다. 이를 통해 프로젝트의 엔트로피를 지속적으로 낮추고 기술 부채를 효과적으로 청산할 수 있다.4. 기술(Skills) 샌드박스와 하위 에이전트(Subagents)를 활용한 병렬화 및 권한 제어에이전트에게 전체 파일 시스템에 대한 읽기/쓰기 권한을 무제한으로 부여하는 것은 시스템 파괴와 같은 치명적인 리스크를 내포한다. Claude Code 사용자는 제공되는 하네스 구조를 활용하여 목적에 맞게 도구 접근을 제한한 전문화된 하위 에이전트를 구성해야 한다.예를 들어, 코드베이스를 수정하지 않고 아키텍처 감사만을 수행하는 '안전한 리뷰어' 기술(Skill)을 생성할 수 있다. ~/.claude/skills/safe-reviewer/SKILL.md 파일을 생성하고, YAML 프런트매터에 allowed-tools: Read, Grep, Glob으로 명시하여 파일 시스템을 조작할 수 있는 쓰기 권한을 원천적으로 차단한다. 더 나아가, 프런트매터에 context: fork 속성과 함께 agent: Explore를 지정하면, 이 기술이 호출될 때 메인 채팅의 컨텍스트 윈도우를 공유하지 않고 독립적으로 생성된 하위 에이전트가 작업을 전담하게 된다.사용자는 메인 세션에서 코드를 작성하다가 "/safe-reviewer $ARGUMENTS(특정 파일)" 명령을 실행하면, 하위 에이전트가 백그라운드에서 해당 파일들을 심층 분석하여 아키텍처 위반 여부만을 보고하고 사라진다. 이렇게 하면 메인 에이전트의 컨텍스트가 오염되는 것을 방지하면서도 필요한 심도 있는 검증을 병렬적으로 수행하는 고도화된 하네스 구조를 구축할 수 있다.하네스 엔지니어링의 2차/3차 파급 효과 및 아키텍처적 시사점하네스 엔지니어링 방법론이 실제 현업 프로젝트에 광범위하게 도입됨에 따라, 소프트웨어 개발 생태계에는 표면적인 코드 생산량 증가 이상의 다차원적이고 구조적인 파급 효과가 나타나고 있다.가장 먼저 두드러지는 변화는 생산성 지표에 대한 근본적인 재평가이다. AI의 지원을 통해 코드의 대량 생성 자체는 비약적으로 쉬워졌으나, 생성된 코드가 기존 시스템에 적합하게 통합되는지를 검증하는 과정으로 개발자의 인지적 부하(Cognitive Load)가 이동했다. 실증적 연구에 따르면, 전문 개발자들이 하네스 제어 없이 최신 AI 도구를 활용하여 복잡한 오픈소스 프로젝트에서 작업을 수행했을 때, 코드 작성의 마찰은 줄어들었지만 미묘하게 잘못된 로직을 디버깅하고 암묵적인 아키텍처 제약과 충돌하는 문제를 해결하느라 역설적으로 전체 작업 완료 시간이 19% 더 증가하는 현상이 관찰되었다. 흥미로운 점은 작업 시간이 객관적으로 증가했음에도 불구하고, 개발자들은 AI 덕분에 오히려 20%의 시간을 단축했다고 착각하는 '속도의 환상(Illusion of Speed)'에 빠져 있었다는 것이다. 이는 코드베이스의 역사와 설계 철학이 에이전트에게 제대로 전달되지 않을 때 발생하는 '문맥 부채(Context Debt)'의 비용을 인간이 과소평가하기 때문이다. 하네스 엔지니어링은 이러한 문맥 부채를 시스템 차원에서 명문화하고 통제함으로써, 속도의 환상이 아닌 실제적인 생산성 향상으로 이어지게 하는 필수적인 연결 고리이다.이러한 맥락에서 '하네스의 서비스화(HaaS: Harness as a Service)'라는 새로운 아키텍처 계층과 패러다임이 부상하고 있다. 과거에는 더 큰 매개변수를 가진 똑똑한 단일 LLM을 확보하는 것이 경쟁력의 척도였으나, 이제는 프런티어 모델들의 성능이 평준화되면서 실제 상용 환경의 복잡성을 돌파하는 핵심 동력이 하네스의 정밀도로 이동하고 있다. 모델의 변동성 심한 지능을 비즈니스 가치로 변환하기 위해서는 에이전트의 자가 검증 메커니즘, 장기 상태 추적 파이프라인, 오류 발생 시의 회복 탄력성(Resilience), 그리고 외부 도구와의 오케스트레이션을 제어하는 하네스 설계 능력이 훨씬 중요해진 것이다. 향후에는 언어 모델 그 자체보다도, 에이전트가 안전하게 활동할 수 있는 샌드박스의 견고함과 모델이 추론을 잃지 않도록 적재적소에 컨텍스트를 주입하는 하네스 인프라 계층이 기업 AI 시스템의 진정한 차별화 요소이자 경제적 해자(Moat)를 형성하게 될 것이다.결론적으로, AI 코딩 어시스턴트는 이제 단편적인 자동 완성 도구를 뛰어넘어 강력한 자율성을 지닌 지능형 에이전트로 진화했으며, 이에 따라 인간 개발자의 역할은 지시자에서 시스템 생태계를 통제하는 아키텍트로 근본적으로 탈바꿈하였다. 앞서 분석한 OpenAI와 Anthropic의 고도화된 프레임워크 사례에서 명확히 드러나듯, 하네스 엔지니어링은 컨텍스트 제어, 아키텍처 제약 강제, 상태의 장기 추적, 그리고 가비지 컬렉션을 통한 엔트로피 통제 등 전통적인 시스템 엔지니어링의 정수를 AI 에이전트 오케스트레이션에 이식하는 필수불가결한 과정이다. 엄격히 통제되지 않은 자율성은 필연적으로 돌이킬 수 없는 기술 부채와 치명적인 코드 드리프트를 낳는다. 폭발적으로 성장하는 LLM의 창조적 역량을 파괴적이지 않고 지속 가능하며 신뢰할 수 있는 소프트웨어 자산으로 온전히 치환하기 위해서는, 단단한 뼈대와 정밀한 제동 장치를 제공하는 하네스 엔지니어링이 모든 AI 개발 파이프라인의 핵심 토대로 확고히 자리매김해야 할 것이다.